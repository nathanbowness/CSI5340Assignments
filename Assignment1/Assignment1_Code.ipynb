{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy;\n",
    "import math;\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot = False\n",
    "\n",
    "def getData(N, variance):\n",
    "    \"\"\"\n",
    "    Generates a dataset {(xi, yi) : i = 1, 2, . . .N} of N (X, Y ) pairs for a given value of N and sigma^2\n",
    "    :return: The generated dataset of (X,Y) pairs\n",
    "    \"\"\"\n",
    "    X = numpy.random.rand(N) # N values between 0 and 1\n",
    "    Z = numpy.random.normal(0, math.sqrt(variance), N) # Zero mean Gaussian random variable, with standard deviation, of length N\n",
    "    Y = numpy.cos(2*math.pi*X) + Z # Y generated from function (1)\n",
    "    #print(\"X: \", X)\n",
    "    #print(\"Z: \", Z)\n",
    "    #print (\"Y: \", Y)\n",
    "\n",
    "    # store the (X,Y) pairs in a N x 2 matrix\n",
    "    x_y_pair_matrix = numpy.column_stack((X, Y))\n",
    "    #print(\"(X,Y) pairs:\", x_y_pair_matrix)\n",
    "    # optionally plot the dataset that is created\n",
    "    if plot:\n",
    "        plt.scatter(X,Y, label=\"My Random Dataset\", marker='x')\n",
    "        plt.title('Generated Dataset for cos(2*pi*x) from 0 to 1')\n",
    "    return x_y_pair_matrix\n",
    "\n",
    "def getMSE(data_set, poly_coefficients):\n",
    "    X_values = numpy.array(data_set[:, 0]) # Values of x from given dataset\n",
    "    y_true_values = numpy.array(data_set[:, 1]) # Values of y from given dataset\n",
    "\n",
    "    # Vandermonde matrix of the function, multiplied by the weights/coefficients gives y_pred\n",
    "    vander_matrix = numpy.vander(X_values, len(poly_coefficients), True)\n",
    "    y_pred = vander_matrix.dot(poly_coefficients) \n",
    "\n",
    "    # MSE calculation using numpy, but will manually calculate below\n",
    "    mse = numpy.mean((y_true_values - y_pred)**2) \n",
    "    #print (\"getMSE_Updated - Auto MSE:\", mse)\n",
    "\n",
    "    # Sum all the squared differences of each y_pred, y_true. Then average that over the vector length, N \n",
    "    summation_diffs_squared = 0\n",
    "    for y_pred_i, y_true_i in zip(y_pred, y_true_values):\n",
    "        squared_diff = (y_pred_i - y_true_i) ** 2\n",
    "        summation_diffs_squared += squared_diff\n",
    "    mse = summation_diffs_squared / len(y_true_values)\n",
    "    #print (\"getMSE_Updated - Manual MSE: \", mse)\n",
    "    return mse\n",
    "\n",
    "def getMSEOld(y_predicted, y_true): # this is probably won't be needed!!!\n",
    "    \"\"\"\n",
    "    Get the Mean Square Error (MSE) loss from the predicted dataset, and the true dataset\n",
    "    :return: The Mean Square Error (MSE)\n",
    "    \"\"\"\n",
    "    # MSE calculation using numpy, but will manually calculate below\n",
    "    mse = numpy.mean((y_true - y_predicted)**2) \n",
    "    #print (\"getMSEOld - MSE:\", mse)\n",
    "    return mse\n",
    "\n",
    "def fitData(data_set, degree_poly, test_dataset):\n",
    "    \"\"\"\n",
    "    fitData method that estimates the polynomial coefficients by fitting a given data to a degree-d polynomial\n",
    "    :return: estimated_coefficients, Ein (MSE), Eout\n",
    "    \"\"\"\n",
    "    # Hyperparameters of GD\n",
    "    learning_rate = 0.1\n",
    "    iterations = 1000\n",
    "    X_values = numpy.array(data_set[:, 0]) # Values of x from given dataset, vector is 1xN\n",
    "    Y_values = numpy.array(data_set[:, 1]) # Values of y from given dataset, vector is 1xN\n",
    "    N = len(Y_values)\n",
    "    #print(\"Real X values:\\n\", X_values)\n",
    "    #print(\"Real Y values:\\n\", Y_values)\n",
    "\n",
    "    # Random starting coefficents\n",
    "    weights = startingRandomCoeffs(degree_poly+1) # vector is 1xD\n",
    "    #print(\"Staring Weights:\\n\", weights)\n",
    "\n",
    "    X_polynomial = numpy.poly1d(weights)\n",
    "    #print(\"Poly function auto\\n\", X_polynomial, \"\\n\")\n",
    "\n",
    "    # Vandermonde matrix, for all X values, without coefficients of N X (D+1) size\n",
    "    vander_matrix = numpy.vander(X_values, degree_poly+1, True)\n",
    "    #print(\"Vander Matrix:\\n\", vander_matrix)\n",
    "\n",
    "    Y_pred = vander_matrix.dot(weights)\n",
    "    for x in range(iterations):\n",
    "\n",
    "        Y_pred = vander_matrix.dot(weights)\n",
    "        grad = 2*(learning_rate/N) * ((Y_values - Y_pred)).dot(vander_matrix)\n",
    "        weights += grad\n",
    "        #if x % 500 == 0:\n",
    "            #print(\"Predicted Y values:\\n\", Y_pred)\n",
    "            #print(\"Current MSE:\", getMSEOld(Y_pred, Y_values))\n",
    "            #print(\"Gradients:\\n\", grad)\n",
    "\n",
    "    if plot:\n",
    "        plt.scatter(X_values,Y_pred, label=\"My Random Dataset\", marker='o')\n",
    "        plt.title('Predicted Y Values')\n",
    "\n",
    "    #print(\"------ Final MSE Values -------\")\n",
    "    Y_pred = vander_matrix.dot(weights)\n",
    "    getMSEOld(Y_pred, Y_values)\n",
    "\n",
    "    Ein = getMSE(data_set, weights)\n",
    "    Eout = getMSE(test_dataset, weights)\n",
    "    return weights, Ein, Eout # this should be changed to the eventual estimated coefficients\n",
    "\n",
    "def startingRandomCoeffs(d):\n",
    "    \"\"\"\n",
    "    Get starting random coefficients, a0, a1, ..., ad, for the polynomial regression function\n",
    "    :return: Randome coefficients for the polynomial based on random values between 0 and 1\n",
    "    \"\"\"\n",
    "    return numpy.random.rand(d)\n",
    "\n",
    "def experiment(N, d, variance):\n",
    "    \"\"\"\n",
    "    Takes as input the size N of training dataset, the degree d of the model polynomial and noise variance σ^2.\n",
    "    For given values, loops over M=50 trials, where each trial generates a dataset of size N with variance, σ^2, \n",
    "    and then fitting the data to a polynomial of degree d.\n",
    "\n",
    "    :return: Output the average Ein_bar, Eout_bar which is the average Ein and Eout over M trials run after fitting the polynomial to the data\n",
    "    \"\"\"\n",
    "    Ein_array = []\n",
    "    Eout_array = []\n",
    "    M = 50\n",
    "\n",
    "    for i in range(M):\n",
    "        training_dataset = getData(N, variance)\n",
    "        test_dataset = getData(2000, variance)\n",
    "        coeff,Ein_i,Eout_i = fitData(training_dataset, d, test_dataset)\n",
    "        Ein_array.append(Ein_i)\n",
    "        Eout_array.append(Eout_i)\n",
    "\n",
    "    Ein_bar = numpy.mean(Ein_array)\n",
    "    Eout_bar = numpy.mean(Eout_array)\n",
    "    return Ein_bar, Eout_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\AppData\\Local\\Temp\\ipykernel_9492\\187539522.py:56: RuntimeWarning: overflow encountered in square\n",
      "  mse = numpy.mean((y_true - y_predicted)**2)\n",
      "C:\\Users\\Nathan\\AppData\\Local\\Temp\\ipykernel_9492\\187539522.py:38: RuntimeWarning: overflow encountered in square\n",
      "  mse = numpy.mean((y_true_values - y_pred)**2)\n",
      "C:\\Users\\Nathan\\AppData\\Local\\Temp\\ipykernel_9492\\187539522.py:44: RuntimeWarning: overflow encountered in double_scalars\n",
      "  squared_diff = (y_pred_i - y_true_i) ** 2\n",
      "C:\\Users\\Nathan\\AppData\\Local\\Temp\\ipykernel_9492\\187539522.py:90: RuntimeWarning: invalid value encountered in add\n",
      "  weights += grad\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#N = 2000      # Size of the training dataset\n",
    "#variance = 0.2  # Variance, sigma^2\n",
    "#degree_d=3    # Degree of the model polynomial\n",
    "\n",
    "# data_set = getData(N, variance)\n",
    "# test_dataset = getData(2000, variance)\n",
    "# M = 35      # Number of trials\n",
    "# est_coeff,Ein,Eout = fitData(data_set, degree_d, test_dataset)\n",
    "\n",
    "N_values = [2, 5, 10, 20, 50, 100, 200]\n",
    "d_values = [1, 2, 4, 8, 16, 32, 64]\n",
    "variance_values = [0.05, 0.2]\n",
    "\n",
    "for N in N_values:\n",
    "    for d in d_values:\n",
    "        for variance in variance_values:\n",
    "            Ein_bar, Eout_bar = experiment(N, d, variance)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
