{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MNIST and CIFAR10 Datasets\n",
    "- Both datasets will be loaded from the torch.vision python package to make the import easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Datasets\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Use GPU as the device if possible\n",
    "default_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(default_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_batch_size = 64\n",
    "image_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "# MNIST transform to preprocess the data\n",
    "transform_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))])\n",
    "\n",
    "def normalize(x):\n",
    "    # x = x / 255\n",
    "    return x\n",
    "\n",
    "# Download and load the training data\n",
    "trainset_mnist = datasets.MNIST('./data/MNIST_data/', download=True, train=True, transform=transform_mnist)\n",
    "trainset_mnist.data = normalize(trainset_mnist.data)\n",
    "trainloader_mnist = torch.utils.data.DataLoader(trainset_mnist, batch_size=default_batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset_mnist = datasets.MNIST('./data/MNIST_data/', download=True, train=False, transform=transform_mnist)\n",
    "testset_mnist.data = normalize(testset_mnist.data)\n",
    "testloader_mnist = torch.utils.data.DataLoader(testset_mnist, batch_size=default_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CIFAR 10\n",
    "# Cifar transform to preprocess the data\n",
    "transcform_cifar_norm = transforms.Normalize((0.5,0.5, 0.5),(0.5, 0.5, 0.5)).to(default_device)\n",
    "transform_cifar = transforms.Compose([transforms.ToTensor(), \n",
    "                                      transcform_cifar_norm])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset_cifar = datasets.CIFAR10('./data/CIFAR10_data/', download=True, train=True, transform=transform_cifar)\n",
    "trainloader_cifar = torch.utils.data.DataLoader(trainset_cifar, batch_size=default_batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset_cifar = datasets.CIFAR10('./data/CIFAR10_data/', download=True, train=False, transform=transform_cifar)\n",
    "testloader_cifar = torch.utils.data.DataLoader(testset_cifar, batch_size=default_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Model Definition\n",
    "class VAE_linear(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size, dropout_rate=0.2):\n",
    "        super(VAE_linear, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size, device=default_device),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size, device=default_device),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, latent_size * 2, device=default_device))  # x2 for mean and variance\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size, device=default_device),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size, device=default_device),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, input_size, device=default_device),\n",
    "            nn.Sigmoid()  # Sigmoid activation for pixel values between 0 and 1\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std, device=default_device)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encoding = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(encoding, 2, dim=1)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        # Decode\n",
    "        reconstruction = self.decoder(z)\n",
    "\n",
    "        return reconstruction, mu, log_var\n",
    "\n",
    "\n",
    "class VAE_conv(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size):\n",
    "        super(VAE_conv, self).__init__()\n",
    "        channel_size = 32\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, channel_size, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channel_size, channel_size * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channel_size * 2, channel_size * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channel_size * 4 * 4 * 4, latent_size * 2)  # Adjusted for mu and log_var\n",
    "        ).to(default_device)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, channel_size * 4 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (channel_size * 4, 4, 4)),\n",
    "            nn.ConvTranspose2d(channel_size * 4, channel_size * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(channel_size * 2, channel_size, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(channel_size, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        ).to(default_device)\n",
    "\n",
    "        # Latent space\n",
    "        self.fc_mu = nn.Linear(hidden_size, latent_size).to(default_device)\n",
    "        self.fc_log_var = nn.Linear(hidden_size, latent_size).to(default_device)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        x = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(x, 2, dim=1)  # Split into mu and log_var\n",
    "\n",
    "        # Reparameterization trick\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        # Decode\n",
    "        x_recon = self.decoder(z)\n",
    "\n",
    "        return x_recon, mu, log_var\n",
    "\n",
    "# VAE Loss function\n",
    "def vae_loss_function(recon_x, x, mu, log_var, input_size):\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, input_size), reduction='sum')\n",
    "\n",
    "    # KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return (BCE, KLD)\n",
    "\n",
    "# VAE Training function\n",
    "def train_vae_linear(model, trainloader, optimizer, num_epochs, input_size):\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(-1, input_size).to(default_device)\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "            # PyTorch accumulates gradients on subsequent backward passes - so zero the grads\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            recon_batch, mu, log_var = model(inputs)\n",
    "\n",
    "            # Binary cross entropy, KL divergence\n",
    "            (BCE, KLD) = vae_loss_function(recon_batch, inputs, mu, log_var, input_size)\n",
    "            totalloss = BCE + KLD\n",
    "\n",
    "            # Backward pass\n",
    "            totalloss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], BCE: {:.4f}, KLD: {:.4f}, Total Loss: {:.4f}'\n",
    "                    .format(epoch+1, num_epochs, i+1, len(trainloader), BCE.item(), KLD.item(), totalloss.item()))\n",
    "\n",
    "def vae_loss_function_conv(recon_x, x, mu, log_var):\n",
    "    # Flatten recon_x to match the shape of x\n",
    "    recon_x_flat = recon_x.view(x.size())\n",
    "\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x_flat, x, reduction='sum')\n",
    "\n",
    "    # KL Divergence\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "    return (BCE, KLD)\n",
    "\n",
    "def train_vae_conv(model, trainloader, optimizer, num_epochs, input_size):\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(default_device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            recon_batch, mu, log_var = model(inputs)\n",
    "\n",
    "            # Reshape the inputs for the loss function\n",
    "            inputs_flat = inputs.view(-1, 3, 32, 32)\n",
    "            recon_batch_flat = recon_batch.view(-1, 3, 32, 32)\n",
    "\n",
    "            # Binary cross entropy, KL divergence\n",
    "            (BCE, KLD) = vae_loss_function_conv(recon_batch_flat, inputs, mu, log_var)\n",
    "            loss = BCE + KLD\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], BCE: {:.4f}, KLD: {:.4f}, Total Loss: {:.4f}'\n",
    "                    .format(epoch+1, num_epochs, i+1, len(trainloader), BCE.item(), KLD.item(), loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Models - MNIST\n",
    "Start training the VAE, GAN and WGAN models with the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Data Training\n",
    "input_size = 28 * 28 # Size of MNIST images - 784\n",
    "hidden_size = 512 # Hidden size for hidden layer\n",
    "latent_size = 128 # Latent size for latent vector -- trial [2, 64, 128]\n",
    "learning_rate = 0.001 # Learning rate for the optimizer\n",
    "num_epochs = 1 # Number of epochs to train for\n",
    "\n",
    "# Initialize the model\n",
    "vae_model_mnist = VAE_linear(input_size, hidden_size, latent_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(vae_model_mnist.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_vae_linear(vae_model_mnist, trainloader_mnist, optimizer, num_epochs, input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR 10 Data Training - Linear\n",
    "input_size = 32 * 32 * 3 # Size of CIFAR images - 3072\n",
    "hidden_size = 512 # Hidden size for hidden layer\n",
    "latent_size = 512 # Latent size for latent vector\n",
    "learning_rate = 0.001 # Learning rate for the optimizer\n",
    "num_epochs = 1 # Number of epochs to train for\n",
    "\n",
    "# Initialize the model\n",
    "vae_model_cifar_linear = VAE_linear(input_size, hidden_size, latent_size)\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(vae_model_cifar_linear.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_vae_linear(vae_model_cifar_linear, trainloader_cifar, optimizer, num_epochs, input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR 10 Data Training - Conv\n",
    "input_size = 32 * 32 * 3 # Size of CIFAR images - 3072\n",
    "hidden_size = 512 # Hidden size for hidden layer ** relationship in the cnn architecture so can't just change this\n",
    "latent_size = 512 # Latent size for latent vector -- trial [2, 64, 128]\n",
    "learning_rate = 0.001 # Learning rate for the optimizer\n",
    "num_epochs = 1 # Number of epochs to train for\n",
    "\n",
    "# CNN\n",
    "\n",
    "# Initialize the model\n",
    "vae_model_cifar = VAE_conv(input_size, hidden_size, latent_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(vae_model_cifar.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_vae_conv(vae_model_cifar, trainloader_cifar, optimizer, num_epochs, input_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def vae_create_original_and_reconstructed_images_arrays(model, testloader, input_size):\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize lists to store original and reconstructed images for testing\n",
    "    test_original_images = []\n",
    "    test_reconstructed_images = []\n",
    "\n",
    "    # Calculate the average reconstruction loss on the testing dataset\n",
    "    test_average_loss = 0.0\n",
    "    test_num_batches = 0\n",
    "\n",
    "    # Evaluate on the entire testing dataset\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(-1, input_size).to(default_device)\n",
    "            \n",
    "            # Forward pass\n",
    "            recon_batch, mu, log_var = vae_model_mnist(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            (BCE, KLD) = vae_loss_function(recon_batch, inputs, mu, log_var, input_size)\n",
    "            loss = BCE + KLD\n",
    "            test_average_loss += loss.item()\n",
    "            test_num_batches += 1\n",
    "\n",
    "            # Convert to numpy arrays for visualization\n",
    "            test_original_images.append(inputs.cpu().numpy())\n",
    "            test_reconstructed_images.append(recon_batch.cpu().numpy())\n",
    "\n",
    "    # Concatenate the batches\n",
    "    test_original_images = np.concatenate(test_original_images, axis=0)\n",
    "    test_reconstructed_images = np.concatenate(test_reconstructed_images, axis=0)\n",
    "\n",
    "    test_average_loss /= test_num_batches\n",
    "    print('Average loss: {:.4f}'.format(test_average_loss))\n",
    "    return test_original_images, test_reconstructed_images, test_average_loss\n",
    "\n",
    "def vae_visualize_original_and_reconstructed(original_images, reconstructed_images, shape, n_samples=10):\n",
    "    # Select n random images\n",
    "    indices = np.random.choice(len(original_images), n_samples, replace=False)\n",
    "\n",
    "    # Plot the original images\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(15, 4))\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        axes[0, i].imshow(original_images[index].reshape(shape), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title('Original')\n",
    "\n",
    "        axes[1, i].imshow(reconstructed_images[index].reshape(shape), cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title('Reconstruct')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize the original and reconstructed images -- MNIST\n",
    "test_original_images, test_reconstructed_images, test_average_loss = vae_create_original_and_reconstructed_images_arrays(vae_model_mnist, testloader_mnist, input_size)\n",
    "vae_visualize_original_and_reconstructed(test_original_images, test_reconstructed_images, shape=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def generate_and_show_cifar(vae_model, data_loader, num_rows=5):\n",
    "    vae_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of real images\n",
    "        real_images, _ = next(iter(data_loader))\n",
    "        real_images = real_images.to(default_device)\n",
    "\n",
    "        # Generate images using the VAE\n",
    "        recon_images, _, _ = vae_model(real_images)\n",
    "\n",
    "    # Display the images\n",
    "    fig, axes = plt.subplots(num_rows, 2, figsize=(10, 2 * num_rows))\n",
    "    for i in range(num_rows):\n",
    "        # Display real images\n",
    "        axes[i, 0].imshow(torchvision.utils.make_grid(real_images[i].cpu(), nrow=1).permute(1, 2, 0))\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title('Real Image')\n",
    "\n",
    "        # Display generated images\n",
    "        axes[i, 1].imshow(torchvision.utils.make_grid(recon_images[i].cpu(), nrow=1).permute(1, 2, 0))\n",
    "        axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title('Generated Image')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming your VAE model and DataLoader are already defined\n",
    "generate_and_show_cifar(vae_model_cifar, testloader_cifar, num_rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to show the images in the training set, versus the linear images\n",
    "\n",
    "# Function to unnormalize and display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Function to generate and display reconstructed images from the VAE\n",
    "def generate_and_show_cifar_linear(vae_model, data_loader, num_rows=1):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            # Display original images\n",
    "            print('Original Images:')\n",
    "            imshow(torchvision.utils.make_grid(images, nrow=num_rows))\n",
    "\n",
    "            # Forward pass through the VAE\n",
    "            images = images.view(-1, 3 * 32 * 32).to(default_device)\n",
    "            recon_images, _, _ = vae_model(images)\n",
    "\n",
    "            # Reshape reconstructed images for visualization\n",
    "            recon_images = recon_images.view(-1, 3, 32, 32)\n",
    "\n",
    "            # Display reconstructed images\n",
    "            print('Reconstructed Images:')\n",
    "            imshow(torchvision.utils.make_grid(recon_images.cpu(), nrow=num_rows))\n",
    "            break  # Break after the first batch for demonstration purposes\n",
    "\n",
    "\n",
    "\n",
    "# Compare trained and untrained images\n",
    "generate_and_show_cifar_linear(vae_model_cifar_linear, testloader_cifar, num_rows=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN - CIFAR\n",
    "Train the GAN model on the CIFAR dataset, and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC GAN\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, feature_size, channels_img):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(z_dim, feature_size * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(feature_size*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(feature_size * 8, feature_size * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( feature_size * 4, feature_size * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( feature_size * 2, feature_size, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( feature_size, channels_img, 3, 1, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        ).to(default_device)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feature_size=64, channels_img=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is ``(nc) x 64 x 64``\n",
    "            nn.Conv2d(channels_img, feature_size, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf) x 32 x 32``\n",
    "            nn.Conv2d(feature_size, feature_size * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*2) x 16 x 16``\n",
    "            nn.Conv2d(feature_size * 2, feature_size * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*4) x 8 x 8``\n",
    "            nn.Conv2d(feature_size * 4, feature_size * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. ``(ndf*8) x 4 x 4``\n",
    "            nn.Conv2d(feature_size * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        ).to(default_device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def training_loop_gan(generator, discriminator, optimG, optimD, img_channels=3, dataset=trainloader_cifar):\n",
    "    # Training Loop\n",
    "    # Hyperparameters\n",
    "    z_dim = 100 # latent vector dimension\n",
    "    img_channels = img_channels\n",
    "    hidden_dim_feature_map = 64 # Size of the image (feature maps) at the last layer of the generator and first layer of the discriminator\n",
    "    lr = 0.0002\n",
    "    batch_size = 64\n",
    "    num_epochs = 5\n",
    "\n",
    "    # Initialize the ``BCELoss`` function\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Create batch of latent vectors that we will use to visualize\n",
    "    #  the progression of the generator\n",
    "    fixed_noise = torch.randn(64, z_dim, 1, 1, device=default_device)\n",
    "\n",
    "    # Establish convention for real and fake labels during training\n",
    "    real_label = 1.\n",
    "    fake_label = 0.\n",
    "\n",
    "    # Setup Adam optimizers for both G and D\n",
    "    optimizerD = optimD\n",
    "    optimizerG = optimG\n",
    "\n",
    "    # Lists to keep track of progress\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    jsd_list = []\n",
    "    iters = 0\n",
    "\n",
    "    print(\"Starting Training Loop...\")\n",
    "    # For each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        # For each batch in the dataloader\n",
    "        for i, data in enumerate(dataset, 0):\n",
    "\n",
    "            ############################\n",
    "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            ###########################\n",
    "            ## Train with all-real batch\n",
    "            discriminator.zero_grad()\n",
    "            # Format batch\n",
    "            real_cpu = data[0].to(default_device)\n",
    "            b_size = real_cpu.size(0)\n",
    "            label = torch.full((b_size,), real_label, dtype=torch.float, device=default_device)\n",
    "            # Forward pass real batch through D\n",
    "            output = discriminator(real_cpu).view(-1)\n",
    "            # Calculate loss on all-real batch\n",
    "            errD_real = criterion(output, label)\n",
    "            # Calculate gradients for D in backward pass\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            ## Train with all-fake batch\n",
    "            # Generate batch of latent vectors\n",
    "            noise = torch.randn(b_size, z_dim, 1, 1, device=default_device)\n",
    "            # Generate fake image batch with G\n",
    "            fake = generator(noise)\n",
    "            #label.fill_(fake_label)\n",
    "\n",
    "            label = torch.full((b_size,), fake_label, dtype=torch.float, device=default_device)\n",
    "\n",
    "            # Classify all fake batch with D\n",
    "            output = discriminator(fake.detach()).view(-1)\n",
    "            # Calculate D's loss on the all-fake batch\n",
    "            errD_fake = criterion(output, label)\n",
    "            # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            # Compute error of D as sum over the fake and the real batches\n",
    "            errD = errD_real + errD_fake\n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network: maximize log(D(G(z)))\n",
    "            ###########################\n",
    "            generator.zero_grad()\n",
    "            label.fill_(real_label)  # fake labels are real for generator cost\n",
    "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "            output = discriminator(fake).view(-1)\n",
    "            # Calculate G's loss based on this output\n",
    "            errG = criterion(output, label)\n",
    "            # Calculate gradients for G\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            # Update G\n",
    "            optimizerG.step()\n",
    "\n",
    "            # Compute JSD\n",
    "            JSD = D_x - 0.5 * (D_G_z1 + D_G_z2)\n",
    "            jsd_list.append(JSD)\n",
    "\n",
    "            # Output training stats\n",
    "            if i % 500 == 0:\n",
    "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tJSD: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                    % (epoch, num_epochs, i, len(dataset),\n",
    "                        errD.item(), errG.item(), D_x, JSD, D_G_z1, D_G_z2))\n",
    "\n",
    "            # Save Losses for plotting later\n",
    "            G_losses.append(errG.item())\n",
    "            D_losses.append(errD.item())\n",
    "\n",
    "            # Check how the generator is doing by saving G's output on fixed_noise\n",
    "            if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataset)-1)):\n",
    "                with torch.no_grad():\n",
    "                    fake = generator(fixed_noise).detach().cpu()\n",
    "                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "            iters += 1\n",
    "    return img_list, G_losses, D_losses, jsd_list \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator and discriminator and apply the weights_init function\n",
    "generator_cifar = Generator(z_dim, hidden_dim_feature_map, img_channels).to(default_device)\n",
    "generator_cifar.apply(weights_init)\n",
    "discriminator_cifar = Discriminator(hidden_dim_feature_map, img_channels)\n",
    "discriminator_cifar.apply(weights_init)\n",
    "\n",
    "optimizerD_cifar = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG_cifar = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "img_list, G_losses, D_losses, jsd_list = training_loop_gan(generator_cifar, discriminator_cifar, optimizerG_cifar, optimizerD_cifar, img_channels=3, dataset=trainloader_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_every = 50\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(range(0, len(G_losses), plot_every), G_losses[::plot_every],label=\"G\")\n",
    "plt.plot(range(0, len(D_losses), plot_every), D_losses[::plot_every],label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Jenson-Shannon Divergence (JSD) During Training Iterations\")\n",
    "plt.plot(range(0, len(jsd_list), plot_every), jsd_list[::plot_every],label=\"JSD\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"JSD\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(testloader_cifar))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(default_device)[:64], padding=3, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_gan_mnist(generator, discriminator, optimG, optimD, img_channels=1, dataset_loc=trainloader_mnist, z_dim=100):\n",
    "    # Training Loop\n",
    "    # Hyperparameters\n",
    "    batch_size = 64\n",
    "    num_epochs = 5\n",
    "\n",
    "    # Initialize the ``BCELoss`` function\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Create batch of latent vectors that we will use to visualize\n",
    "    #  the progression of the generator\n",
    "    fixed_noise = torch.randn(64, z_dim, 1, 1, device=default_device)\n",
    "\n",
    "    # Establish convention for real and fake labels during training\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "\n",
    "    # Setup Adam optimizers for both G and D\n",
    "    optimizerD = optimD\n",
    "    optimizerG = optimG\n",
    "\n",
    "    # Lists to keep track of progress\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    jsd_list = []\n",
    "    jsd_est_list = []\n",
    "    iters = 0\n",
    "\n",
    "    print(\"Starting Training Loop...\")\n",
    "    # For each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        # For each batch in the dataloader\n",
    "        for i, data in enumerate(dataset_loc, 0):\n",
    "\n",
    "            # Train and update descriminator with the real data sample\n",
    "            discriminator.zero_grad()\n",
    "            # Format batch\n",
    "            real_cpu = data[0].to(default_device)\n",
    "            b_size = real_cpu.size(0)\n",
    "            label = torch.full((b_size,), real_label, dtype=torch.float, device=default_device)\n",
    "            # Forward pass real batch through D\n",
    "            output_real = discriminator(real_cpu).view(-1)\n",
    "            # Calculate loss on all-real batch\n",
    "            errD_real = criterion(output_real, label)\n",
    "            # Calculate gradients for D in backward pass\n",
    "            errD_real.backward()\n",
    "            D_x = output_real.mean().item()\n",
    "\n",
    "            ## Train and update the descriminator with the fake data sample\n",
    "            # Generate batch of random latent vectors\n",
    "            noise = torch.randn(b_size, z_dim, 1, 1, device=default_device)\n",
    "            # Generate fake image batch with G\n",
    "            fake = generator(noise)\n",
    "            label.fill_(fake_label)\n",
    "\n",
    "            # Classify all fake batch with D\n",
    "            output = discriminator(fake.detach()).view(-1)\n",
    "\n",
    "            # Calculate D's loss on the all-fake batch\n",
    "            errD_fake = criterion(output, label)\n",
    "            # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            # Compute error of D as sum over the fake and the real batches\n",
    "            errD = errD_real + errD_fake\n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "\n",
    "            # Update the generator with fake data\n",
    "            generator.zero_grad()\n",
    "            label.fill_(real_label)  # fake labels are real for generator cost\n",
    "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "            output_fake = discriminator(fake).view(-1)\n",
    "            # Calculate G's loss based on this output\n",
    "            errG = criterion(output_fake, label)\n",
    "            # Calculate gradients for G\n",
    "            errG.backward()\n",
    "            D_G_z2 = output_fake.mean().item()\n",
    "            # Update G\n",
    "            optimizerG.step()\n",
    "\n",
    "            # Compute JSD\n",
    "            # JSD = D_x - 0.5 * (D_G_z1 + D_G_z2)\n",
    "            # jsd_list.append(JSD)\n",
    "\n",
    "            M = 0.5 * (output.data.mean() + label.data.mean())\n",
    "            jsd_estimate = 0.5 * (torch.nn.functional.kl_div(output, M) + torch.nn.functional.kl_div(label, M))\n",
    "            jsd_est_list.append(jsd_estimate)\n",
    "\n",
    "            # JSD Calculation\n",
    "            p_real = torch.mean(output_real).item()\n",
    "            p_fake = torch.mean(output_fake).item()\n",
    "            p_mixed = (p_real + p_fake) / 2\n",
    "            jsd = 0.5 * (p_real * torch.log2(torch.tensor(p_real) / torch.tensor(p_mixed)) + \n",
    "                p_fake * torch.log2(torch.tensor(p_fake) / torch.tensor(p_mixed)))\n",
    "            jsd_list.append(jsd)\n",
    "\n",
    "            # Output training stats\n",
    "            if i % 500 == 0:\n",
    "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tJSD: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                    % (epoch, num_epochs, i, len(dataset_loc),\n",
    "                        errD.item(), errG.item(), D_x, jsd, D_G_z1, D_G_z2))\n",
    "\n",
    "            # Save Losses for plotting later\n",
    "            G_losses.append(errG.item())\n",
    "            D_losses.append(errD.item())\n",
    "\n",
    "            # Check how the generator is doing by saving G's output on fixed_noise\n",
    "            if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataset_loc)-1)):\n",
    "                with torch.no_grad():\n",
    "                    fake = generator(fixed_noise).detach().cpu()\n",
    "                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "            iters += 1\n",
    "    return img_list, G_losses, D_losses, jsd_list, jsd_est_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DC GAN\n",
    "class GeneratorMnist(nn.Module):\n",
    "    def __init__(self, z_dim, feature_size, channels_img=1):\n",
    "        super(GeneratorMnist, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is z-dim, going into a convolution\n",
    "            nn.ConvTranspose2d(z_dim, feature_size * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 8),\n",
    "            nn.ReLU(True),\n",
    "            # 1st hidden layer\n",
    "            nn.ConvTranspose2d(feature_size * 8, feature_size * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 4),\n",
    "            nn.ReLU(True),\n",
    "            # 2nd hidden layer\n",
    "            nn.ConvTranspose2d(feature_size * 4, feature_size*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size*2),\n",
    "            nn.ReLU(True),\n",
    "            # 3rd hidden layer\n",
    "            nn.ConvTranspose2d(feature_size * 2, feature_size, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size),\n",
    "            nn.ReLU(True),\n",
    "            # output layer\n",
    "            nn.ConvTranspose2d(feature_size, channels_img, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        ).to(default_device)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class DiscriminatorMnist(nn.Module):\n",
    "    def __init__(self, feature_size, channels_img=1):\n",
    "        super(DiscriminatorMnist, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Conv2d(channels_img, feature_size, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 2nd layer\n",
    "            nn.Conv2d(feature_size, feature_size * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 3rd layer\n",
    "            nn.Conv2d(feature_size * 2, feature_size * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 4th layer\n",
    "            nn.Conv2d(feature_size * 4, feature_size * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_size * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Output layer\n",
    "            nn.Conv2d(feature_size * 8, 1, 3, 2, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        ).to(default_device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GeneratorMnistLinear(nn.Module):\n",
    "#     def __init__(self, z_dim, img_size):\n",
    "#         super(GeneratorMnistLinear, self).__init__()\n",
    "#         self.generator = nn.Sequential(\n",
    "#             nn.Linear(z_dim, 256),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "\n",
    "#             nn.Linear(256, 512),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "\n",
    "#             nn.Linear(512, 1024),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "\n",
    "#             nn.Linear(1024, img_size),\n",
    "#             nn.Tanh(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         return self.generator(input)\n",
    "#         #return self.generator(input).view(-1, 1, 28, 28)\n",
    "#         return self.generator(input).view(-1, 1, int(img_size ** 0.5), int(img_size ** 0.5))\n",
    "\n",
    "# # Discriminator\n",
    "# class DiscriminatorMnistLinear(nn.Module):\n",
    "#     def __init__(self, img_size):\n",
    "#         super(DiscriminatorMnistLinear, self).__init__()\n",
    "#         self.img_size = img_size\n",
    "#         self.discriminator = nn.Sequential(\n",
    "#                 nn.Linear(img_size, 1024),\n",
    "#                 nn.LeakyReLU(0.2),\n",
    "#                 nn.Dropout(0.3),\n",
    "\n",
    "#                 nn.Linear(1024, 512),\n",
    "#                 nn.LeakyReLU(0.2),\n",
    "#                 nn.Dropout(0.3),\n",
    "\n",
    "#                 nn.Linear(512, 256),\n",
    "#                 nn.LeakyReLU(0.2),\n",
    "#                 nn.Dropout(0.3),\n",
    "\n",
    "#                 nn.Linear(256, 1),\n",
    "#                 nn.Sigmoid(),\n",
    "#             )\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         return self.discriminator(input.view(-1, self.n_input))\n",
    "        # return self.discriminator(input)\n",
    "        # return self.discriminator(input.view(-1, self.img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_mnist_training(generator, descriminator):\n",
    "\n",
    "    z_dim = 100\n",
    "    feature_size = 64\n",
    "    lr = 0.0002\n",
    "    batch_size = 64\n",
    "    epochs = 3\n",
    "\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    jsd_list = []\n",
    "\n",
    "    # Define loss function and optimizers\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizerG = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizerD = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (real_images, _) in enumerate(trainloader_mnist):\n",
    "            real_images = real_images.to(default_device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            discriminator.zero_grad()\n",
    "\n",
    "            # Discriminator on real images\n",
    "            output_real = discriminator(real_images)\n",
    "            output_real = output_real.view(-1, 1)\n",
    "            real_labels = torch.ones_like(output_real).to(default_device)\n",
    "            loss_real = criterion(output_real, real_labels)\n",
    "\n",
    "            loss_real.backward()\n",
    "\n",
    "            # Discriminator on fake images\n",
    "            noise = torch.randn(batch_size, z_dim, 1, 1).to(default_device)\n",
    "            fake_images = generator(noise)\n",
    "            output_fake = discriminator(fake_images.detach())\n",
    "            output_fake = output_fake.view(-1, 1)\n",
    "            fake_labels = torch.zeros_like(output_fake).to(default_device)\n",
    "            loss_fake = criterion(output_fake, fake_labels)\n",
    "            loss_fake.backward()\n",
    "\n",
    "            optimizerD.step()\n",
    "\n",
    "            # Train Generator\n",
    "            generator.zero_grad()\n",
    "            output_generated = discriminator(fake_images)\n",
    "            output_generated = output_generated.view(-1, 1)\n",
    "            real_labels = torch.ones_like(output_generated).to(default_device)\n",
    "            loss_generator = criterion(output_generated, real_labels)\n",
    "            loss_generator.backward()\n",
    "\n",
    "            optimizerG.step()\n",
    "\n",
    "            # JSD Calculation\n",
    "            p_real = torch.mean(output_real).item()\n",
    "            p_fake = torch.mean(output_fake).item()\n",
    "            p_mixed = (p_real + p_fake) / 2\n",
    "            jsd = 0.5 * (p_real * torch.log2(torch.tensor(p_real) / torch.tensor(p_mixed)) + \n",
    "                p_fake * torch.log2(torch.tensor(p_fake) / torch.tensor(p_mixed)))\n",
    "\n",
    "            # Save Losses for plotting later\n",
    "            G_losses.append(loss_generator.item())\n",
    "            D_losses.append(loss_real.item() + loss_fake.item())\n",
    "            jsd_list.append(jsd)\n",
    "\n",
    "            # Print progress\n",
    "            if batch_idx % 500 == 0:\n",
    "                print(f\"Epoch {epoch}/{epochs}, Batch {batch_idx}/{len(trainloader_mnist)}, \"\n",
    "                    f\"Loss D: {loss_real.item() + loss_fake.item()}, Loss G: {loss_generator.item()}, \"\n",
    "                    f\"JSD: {jsd}\")\n",
    "\n",
    "    return G_losses, D_losses, jsd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "def gan_simple(generator, descriminator, img_size):\n",
    "    z_dim = 100\n",
    "    feature_size = 64\n",
    "    lr = 0.0002\n",
    "    batch_size = 64\n",
    "    epochs = 3\n",
    "\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    jsd_list = []\n",
    "\n",
    "\n",
    "    # Load MNIST dataset\n",
    "    mnist_dataset_local = MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
    "\n",
    "    # Create DataLoader\n",
    "    trainloader_mnist__local = DataLoader(mnist_dataset_local, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    # Define loss function and optimizers\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizerG = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizerD = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (real_images, _) in enumerate(tqdm(trainloader_mnist__local)):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.view(-1, img_size)\n",
    "\n",
    "            # Check for proper data dimensions\n",
    "            if real_images.dim() != 4:\n",
    "                raise ValueError(f\"Expected 4D input, but got {real_images.dim()}D\")\n",
    "\n",
    "            # Training Discriminator\n",
    "            optimizerD.zero_grad()\n",
    "\n",
    "            # Real data\n",
    "            real_outputs = discriminator(real_images)\n",
    "            real_labels = torch.ones_like(output_real).to(default_device)\n",
    "            D_loss_real = criterion(real_outputs, real_labels)\n",
    "            \n",
    "            # Fake data\n",
    "            z = torch.randn(batch_size, z_dim)\n",
    "            fake_images = generator(z)\n",
    "            fake_labels = torch.zeros(batch_size, 1)\n",
    "            fake_outputs = discriminator(fake_images.detach())\n",
    "            D_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "\n",
    "            # Total loss\n",
    "            D_loss = D_loss_real + D_loss_fake\n",
    "            D_loss.backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "            # Training Generator\n",
    "            optimizerG.zero_grad()\n",
    "            \n",
    "            z = torch.randn(batch_size, z_dim)\n",
    "            generated_images = generator(z)\n",
    "            G_loss = criterion(discriminator(generated_images), real_labels)\n",
    "            G_loss.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            # Calculate JSD\n",
    "            p = real_labels.mean().item()\n",
    "            q = fake_labels.mean().item()\n",
    "            m = 0.5 * (p + q)\n",
    "            JSD = 0.5 * (p * torch.log(p / m) + q * torch.log(q / m))\n",
    "\n",
    "            # Save values\n",
    "            jsd_list.append(JSD.item())\n",
    "            G_losses.append(G_loss.item())\n",
    "            D_losses.append(D_loss.item())\n",
    "\n",
    "        # Print statistics\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], JSD: {JSD.item()}, G_loss: {G_loss.item()}, D_loss: {D_loss.item()}\")\n",
    "\n",
    "    return G_losses, D_losses, jsd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator and discriminator and apply the weights_init function\n",
    "z_dim_new = 100\n",
    "feature_size = 64\n",
    "channels = 1\n",
    "\n",
    "# Download and load the training data\n",
    "transform_mnist = transforms.Compose(transforms.Compose([\n",
    "                     transforms.Resize(feature_size),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.5,), (0.5,))\n",
    "                     ]))\n",
    "trainset_mnist_gan = datasets.MNIST(root='./data/MNIST_data/', download=True, train=True, transform=transform_mnist)\n",
    "trainset_mnist_gan.data = normalize(trainset_mnist.data)\n",
    "trainloader_mnist_gan = torch.utils.data.DataLoader(trainset_mnist, batch_size=default_batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "generator_mnist = GeneratorMnist(z_dim_new, feature_size, 1)\n",
    "generator_mnist.apply(weights_init)\n",
    "discriminator_mnist = DiscriminatorMnist(feature_size, 1)\n",
    "discriminator_mnist.apply(weights_init)\n",
    "\n",
    "optimizerD = optim.Adam(discriminator_mnist.parameters(), lr=0.00002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(generator_mnist.parameters(), lr=0.00002, betas=(0.5, 0.999))\n",
    "\n",
    "img_list_mnist, G_losses_mnist, D_losses_mnist, jsd_list_mnist, jsd_est_list = training_loop_gan_mnist(generator_mnist, discriminator_mnist, optimizerG, optimizerD, img_channels=1, dataset_loc=trainloader_mnist_gan, z_dim=z_dim_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(testloader_mnist))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(default_device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list_mnist[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of Generator and Discriminator\n",
    "\n",
    "z_dim_new = 100\n",
    "feature_size = 784\n",
    "image_size = 28 * 28\n",
    "generator_mnist = GeneratorMnistLinear(z_dim, image_size).to(default_device)\n",
    "generator_mnist.apply(weights_init)\n",
    "discriminator_mnist = DiscriminatorMnistLinear(image_size).to(default_device)\n",
    "discriminator_mnist.apply(weights_init)\n",
    "\n",
    "# G_losses_mnist, D_losses_mnist, jsd_list_mnist = gan_mnist_training(generator=generator_mnist, descriminator=discriminator_mnist)\n",
    "G_losses_mnist, D_losses_mnist, jsd_list_mnist = gan_simple(generator=generator_mnist, descriminator=discriminator_mnist, img_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_every_mnist = 2\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(range(0, len(G_losses_mnist), plot_every_mnist), G_losses_mnist[::plot_every_mnist],label=\"G\")\n",
    "plt.plot(range(0, len(D_losses_mnist), plot_every_mnist), D_losses_mnist[::plot_every_mnist],label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Jenson-Shannon Divergence (JSD) During Training Iterations\")\n",
    "plt.plot(range(0, len(jsd_est_list), plot_every_mnist), jsd_est_list[::plot_every_mnist],label=\"JSD\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"JSD\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 10 fake images\n",
    "num_images_to_make = 10\n",
    "img_list = []\n",
    "with torch.no_grad():\n",
    "    generator_mnist.eval()\n",
    "    # Generate batch of latent vectors\n",
    "    noise = torch.randn(64, z_dim, 1, 1, device=default_device)\n",
    "    # Generate fake image batch with G\n",
    "    generated_images = generator_mnist(noise)\n",
    "\n",
    "index = 2  # You can change this to any index you want to visualize\n",
    "# Get the generated image at the selected index\n",
    "generated_image = generated_images[index].squeeze().cpu().numpy()\n",
    "\n",
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(testloader_mnist))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(default_device)[:64], padding=3, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "# Plot the generated image using Matplotlib\n",
    "plt.imshow(generated_image, cmap='gray')\n",
    "plt.title('Generated Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the real images from the test set\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(real_images.to(\"cpu\")[:64], padding=2, normalize=True).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the generated images\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(fake_images.to(\"cpu\")[:64], padding=2, normalize=True).cpu(),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new random noise\n",
    "noise_mnist = torch.randn(batch_size, z_dim, device=default_device)\n",
    "\n",
    "# Generate fake images with the generator\n",
    "generator_mnist.eval()  # Set the generator to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_fake_images = generator_mnist(noise_mnist).detach().cpu()\n",
    "\n",
    "# Plot the generated images\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(\n",
    "        vutils.make_grid(test_fake_images[:64], padding=2, normalize=True),\n",
    "        (1, 2, 0),\n",
    "    )\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN with MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
